{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5670d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037d3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple acquired Zoom in China on Wednesday 6th May 2020.\\\n",
    "This news has made Apple and Google stock jump by 5% on Dow Jones Index in the \\\n",
    "United States of America\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dd878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2acc2d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21858374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Apple', 'NNP'),\n",
       " ('acquired', 'VBD'),\n",
       " ('Zoom', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('China', 'NNP'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('6th', 'CD'),\n",
       " ('May', 'NNP'),\n",
       " ('2020.This', 'CD'),\n",
       " ('news', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('made', 'VBN'),\n",
       " ('Apple', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Google', 'NNP'),\n",
       " ('stock', 'NN'),\n",
       " ('jump', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('5', 'CD'),\n",
       " ('%', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Dow', 'NNP'),\n",
       " ('Jones', 'NNP'),\n",
       " ('Index', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('of', 'IN'),\n",
       " ('America', 'NNP')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags=nltk.pos_tag(words)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ea9b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebcd4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38ee7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2790e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "185c95d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NE Apple/NNP)\n",
      "('acquired', 'VBD')\n",
      "('Zoom', 'NNP')\n",
      "('in', 'IN')\n",
      "(NE China/NNP)\n",
      "('on', 'IN')\n",
      "('Wednesday', 'NNP')\n",
      "('6th', 'CD')\n",
      "('May', 'NNP')\n",
      "('2020.This', 'CD')\n",
      "('news', 'NN')\n",
      "('has', 'VBZ')\n",
      "('made', 'VBN')\n",
      "(NE Apple/NNP)\n",
      "('and', 'CC')\n",
      "(NE Google/NNP)\n",
      "('stock', 'NN')\n",
      "('jump', 'NN')\n",
      "('by', 'IN')\n",
      "('5', 'CD')\n",
      "('%', 'NN')\n",
      "('on', 'IN')\n",
      "('Dow', 'NNP')\n",
      "('Jones', 'NNP')\n",
      "('Index', 'NNP')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "(NE United/NNP States/NNPS)\n",
      "('of', 'IN')\n",
      "(NE America/NNP)\n"
     ]
    }
   ],
   "source": [
    "chunks=nltk.ne_chunk(pos_tags,binary=True)\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790a7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>America</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entities labels\n",
       "0  United States     NE\n",
       "1        America     NE\n",
       "2          Apple     NE\n",
       "3         Google     NE\n",
       "4          China     NE"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities=[]\n",
    "labels=[]\n",
    "for chunk in chunks:\n",
    "    if hasattr(chunk,'label'):\n",
    "        entities.append(' '.join(c[0] for c in chunk))\n",
    "        labels.append(chunk.label())\n",
    "ent_labels=list(set(zip(entities,labels)))\n",
    "ent_df=pd.DataFrame(ent_labels)\n",
    "ent_df.columns=[\"entities\",\"labels\"]\n",
    "ent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f5aa4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON Apple/NNP)\n",
      "('acquired', 'VBD')\n",
      "(PERSON Zoom/NNP)\n",
      "('in', 'IN')\n",
      "(GPE China/NNP)\n",
      "('on', 'IN')\n",
      "('Wednesday', 'NNP')\n",
      "('6th', 'CD')\n",
      "('May', 'NNP')\n",
      "('2020.This', 'CD')\n",
      "('news', 'NN')\n",
      "('has', 'VBZ')\n",
      "('made', 'VBN')\n",
      "(PERSON Apple/NNP)\n",
      "('and', 'CC')\n",
      "(ORGANIZATION Google/NNP)\n",
      "('stock', 'NN')\n",
      "('jump', 'NN')\n",
      "('by', 'IN')\n",
      "('5', 'CD')\n",
      "('%', 'NN')\n",
      "('on', 'IN')\n",
      "(PERSON Dow/NNP Jones/NNP Index/NNP)\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "(GPE United/NNP States/NNPS)\n",
      "('of', 'IN')\n",
      "(GPE America/NNP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>America</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dow Jones Index</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zoom</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Google</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>China</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          entities        labels\n",
       "0          America           GPE\n",
       "1            Apple        PERSON\n",
       "2    United States           GPE\n",
       "3  Dow Jones Index        PERSON\n",
       "4             Zoom        PERSON\n",
       "5           Google  ORGANIZATION\n",
       "6            China           GPE"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=nltk.ne_chunk(pos_tags,binary=False)\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "    entities=[]\n",
    "labels=[]\n",
    "for chunk in chunks:\n",
    "    if hasattr(chunk,'label'):\n",
    "        entities.append(' '.join(c[0] for c in chunk))\n",
    "        labels.append(chunk.label())\n",
    "ent_labels=list(set(zip(entities,labels)))\n",
    "ent_df=pd.DataFrame(ent_labels)\n",
    "ent_df.columns=[\"entities\",\"labels\"]\n",
    "ent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26622ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a0e32fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.5'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64089a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5937b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a6e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "entts=[]\n",
    "lbls=[]\n",
    "for ent in doc.ents:\n",
    "    entts.append(ent)\n",
    "    lbls.append(ent.label_)\n",
    "df=pd.DataFrame({'Entities':entts,'labels':lbls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d465f1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Apple)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Zoom)</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(China)</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Wednesday, 6th, May)</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Apple)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Google)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(5, %)</td>\n",
       "      <td>PERCENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Dow, Jones, Index)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(the, United, States, of, America)</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Entities   labels\n",
       "0                             (Apple)      ORG\n",
       "1                              (Zoom)      GPE\n",
       "2                             (China)      GPE\n",
       "3               (Wednesday, 6th, May)     DATE\n",
       "4                             (Apple)      ORG\n",
       "5                            (Google)      ORG\n",
       "6                              (5, %)  PERCENT\n",
       "7                 (Dow, Jones, Index)      ORG\n",
       "8  (the, United, States, of, America)      GPE"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b1a31c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed560372",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex=''' Pune Police detained Manorama Khedkar, mother of controversial IAS officer Puja Khedkar, on Thursday.\n",
    "Police had been searching for Manorama and her husband Dilip after an FIR was filed against them and five \n",
    "others following the emergence of a video showing Manorama allegedly\n",
    "threatening individuals with a gun over a land dispute.''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8376c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
